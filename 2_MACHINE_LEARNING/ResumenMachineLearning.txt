Configuracion
    Crear ambiente virtual en python
    Instalar:
        numpy
        pandas
        matplotlib
        seaborn
        scikit-learn
        streamlit
        plotly

Tramiento de datos
    Pasar de datos sucios a datos limpios y ordenados

    Tratamientos:
        1. Reemplazar valores (datos vacios, datos nulos, datos negativos)
        2. Imputacion de datos (remplazar con la media, con la moda, con el promedio)
        3. Estandarizar datos (normalizacion datos de 0 a 1, -1 a 1. escalado de datos)
        4. Mapeo de datos (correccion de ortografia, acentos)

    Pasos:
        0. Analizar
            Oler los malos datos, ver rangos, ver los minimos y maximos
                df.describe()
                df.info()
                graficar()

            Analizar los datos categoricos    
                set_gen=set(df['genero'].to_list())

        1. Reemplazar valores. Tratamiento de valores negativos
            df['edad']=df['edad'].apply(lambda x:np.nan if x<0 else x)

        2. Imputacion de datos. Imputar valores faltantes
            median_value=df['edad'].median()
            df['edad'].fillna(median_value)

        3. Estandarizar datos
            Casteo de datos
                df['edad']=df['edad'].astype(int)

        4. Mapeo de datos
            'Bachelors':'Bachelor'
            'mastre':'Master'
            'pHd':'PhD'
            'no education':'None'
        
Analisis exploratorio
    Consultas al dataset
    Ejemplo: dataset de sobreviviente del titanic
        Y como se relacion la edad con la supervivencia
            df.groupby('Suvived')['Age'].mean()
        Cuantos pasajeros sobrevieron y cuantos no?
            df['Survived'].value_counts()
        El genero tiene alguna relacion con la supervivencia?
            df.groupby('Sex')['Survived'].mean()
        La clase del boteto tiene alguna relacion con la supervivencia?
            df.groupby('Pclass')['Survived'].mena()
        El puerto de embarque tiene alguan relacion con la supervivencia?
            df['Embarked'].value_counts()
            df.groupby('Embarked')['Survived'].mean()
        La tarifa tiene alguna relacion con la supervivencia?
            df.groupby('Survived')['Fare'].mean()

Normalizacion de datos
    Escalado
        Cambia el rango de los datos. como [0,1] o bien [-1,1]        
            scaler=MinMaxScaler()
    Normalizacion
        Cambia la distribucion de los datos para que tenga una media 0
            scaler=StandardScaler()

Codificacion de datos categoricos
    One-Hot Enconding
        Crear variables numericas para cada categoria
        Ineficiciente cuando hay muchas catagorias
        Tambien son conocidadas como variables dummy

        encoder=OneHotEncoder()

    Label Enconding
        A cada categoria asigna una valor numerico
        Los algoritmos podrian interpretar como si las categorias tuvieran un orden

        encoder=LabelEncoder()
        encoder=OrdinalEncoder() //hace lo mismo pero en una sola linea de codigo

Conjuntos de entrenamiento y prueba
    Partir el dataset en datos de entrenamiento y pruebas
    Por lo general el tamano del dataset de entrenamiento es entre 60% y 80%
    Tener cuidado con el overfitting

Metricas
    La metrica es una medida para calificar el modelo creado
    Error
        En clasificacion un error de predicion es cuando el modelo da un falso positivo o negativo
        En regresion un error se entiende como una diferencia entre el valor ideal y valor predicho

    Para clasificacion 
        Asertividad(Accuracy)
            Verdadero Positivos (correcto)
            Verdaderos Negativos (correcto)
            Falsos Positivos (incorrecto)
            Falsos Negativos (incorrecto)

            A=True/True+False
                    
        1. Matriz  de confusion
             Es una tabla que se usa para ver el rendimiento del modelo           
             La diagonal principal tiene que tener mayor cantidad de valores correctos


                            Predicho Positivo   Predicho Negativo
             Real Positivos Verdadero Positivo  Falso Negatitvo
             Real Negativo  Falso Positivo      Verdadero Negativo

        2. Precision
            P= True Positive/True Positive + False Positive

        3. Recall (Tasa de verdaderos positivos)
            R=True Positive/True Positive + False Negative

        4. F1-Score (Recall + Precision)
            F1=2(pxR)/p+R            

        5. ROC curve
            Grafica que muestra el rendimiento del modelo            

        Ejemplo:
            Dataset Iris

            1. Calcular la matriz de confusion
            2. Calcular la Precision (matriz de confusion)
            3. Calcular el recall (matriz de confusion)
            4. Calcular F1-Score (Resultado de Precision, Resultado de Recall)
            5. Graficar la ROC curve (lo curva tiene que esta inclinado hacia True Positive Rate)

    Para regresion
        1. Error Cuadratico (SE)
            La suma de los cuadrados de los errores
            El error es la diferencia entre el valor ideal y valor predicho
            Los punto fuera de la recta ideal son las predicciones
        
        2. Error cuadratico medio (MSE)
            Promedio de los cuadrados de los errores

        3. Raiz del error cuadratico medio (RMSE)
            Es la raiz cuadrada del prodmedio de los cuadrados de los errores

        4. Error absoluto medio (MAE)
            Es el promedio de los valores absolutos de los errores

        5. Coeficiente de determinaicon
            Indica cuanta variacion de los datos puede ser explicada por el modelo
            Si el resultado se acerca a 1, quiero decir que el modelo es mejor

        Ejemplo:
            Dataset Salarydata
            1. Error Cuadratico
                EC = ((y_test-y_pred)**2).sum()
            2. Error Cuadratico medio
                ECM=EC/len(y_test)
            3. Raiz del error cuadratico medio
                RMSE = ECM ** 0.5
            4. Erro Absoluto medio
                EAM = abs(y_test - y_pred).mean()
            5. Coeficionente de determinacion
                residuos= y_test-y_pred
                explained_variance=resisudos.var()
                total_variance=y_test.var()
                R2=1-(explained_variance/total_variance)

                Las metricas para regresion 1,2,3,4 son necesarias para llegar a la metrica 5
                La metrica 1 maneja valores grandes es necesario reducir las metricas 2,3,4 para llegar a la metrica 5
                El coeficinete de determiancion es capaz de explicar el 0.97 (97% de los datos) de la variacion de los datos. Buen modelo.
            



VOCABULARIO
Metrica
Media armonica
Clasificacion binaria
ROC curve


